<!DOCTYPE HTML>
<html>
<head>
<title>Hahn AI</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="assets/css/main.css" />
</head>
<body>
<header id="header">
<a href="index.html" class="logo"><strong>Hahn</strong> AI</a>
</header>

<section id="main">
<div class="inner">
<a href = 'blog0.html'><h4>Motor Cognition</h4></a>
<p><span class="image left"><a href = 'blog0.html'><img src="https://drive.google.com/uc?export=download&id=1g-Sr5GXfr6K4pAYL2wkiwaqhC2V0LqYT" alt="" /></a> </span>Motor cognition is the notion that understanding is often grounded in our action capabilities. The roots of the word perception translate to “grasping with mind”. Our ability to move and interact within our environment shapes our mental representations. Often complex behaviors can be derived from simple mechanical linkages, suggesting that seemingly cognitive tasks can be accomplished with simple action-perception loops, i.e. Braitenberg vehicles. Going beyond sensory input, motor cognition considers the structures necessary for the planning and production of actions, as well as recognizing, predicting, and mimicking the actions of others.  <a href = 'blog0.html'>Read More</a></p>
				
</div>
</section>
<br>

<section id="main">
<div class="inner">
<a href = 'blog1.html'><h4>Texture Recognition</h4></a>
<p><span class="image left"><a href = 'blog1.html'><img src="https://drive.google.com/uc?export=download&id=10XKuiUouZ2euQ_mGCgL5_5bz4E3nZyHm" alt="" /></a> </span>Natural images can often be decomposed into cartoon and texture. While much work has been done on edge detection, of equal importance is the ability to recognize and classify different texture patterns. From terrain estimation for autonomous vehicles to medical image analysis, the ability to identify and segment complex textures represents a major challenge for existing image processing techniques. Inspired by the human visual system, sparse dictionary modeling has shown to yield state of the art results in visual discrimination tasks. <a href = 'blog1.html'>Read More</a></p>
				
</div>
</section>
<br>

<section id="main">
<div class="inner">
<a href = 'blog2.html'><h4>Sound Analysis</h4></a>
<p><span class="image left"><a href = 'blog2.html'><img src="https://drive.google.com/uc?export=download&id=1Lbnu-Dclkc-GITFnQX9imJIQHPGZlgju" alt="" /></a> </span>The cocktail party effect refers to the human brain’s ability to selectively tune into a particular conversation amidst many competing conversations and significant background noise. The separation and grouping of acoustic data streams is called auditory scene analysis. Given the current trends in big data it will be come increasingly more important to selectively and dynamically attend to salient subsets of the data. Perceptual binding of music and speech amidst competing background noise is something that the brain can do almost effortlessly but for only a single steam at a time. Machine techniques should allow for the segmentation and binding of multiple streams concurrently. <a href = 'blog2.html'>Read More</a></p>
				
</div>
</section>
<br>

<section id="main">
<div class="inner">
<a href = 'blog3.html'><h4>Video AI</h4></a>
<p><span class="image left"><a href = 'blog3.html'><img src="https://drive.google.com/uc?export=download&id=1vGoMQmSA2rVuyBWLNdXDmiBv2f6R5ZQE" alt="" /></a> </span>It would take an individual over 5 million years to watch the amount of video that will cross the internet each month in 2018, by then, every second, nearly a million minutes of video content will cross the network. Closed circuit television cameras networks have become ubiquitous in many major cities yet most of the data goes unexamined. Video will be in the range of 80 to 90 percent of global internet traffic by 2018. Without automated means to sort and analyze this video data we will be unable to take advantage of humanity’s largest data stream. Compressed sensing and sparse modeling now offer a means to tackle this global deluge. <a href = 'blog3.html'>Read More</a></p>
				
</div>
</section>
<br>

<section id="main">
<div class="inner">
<a href = 'blog4.html'><h4>Tower of Babel: LLM Technology and the Reconciliation of Tongues</h4></a>
<p><span class="image left"><a href = 'blog4.html'><img src="https://drive.google.com/uc?export=download&id=16jQsuvNE8cRgpNZRDyCiFQo6MnYjDzq5" alt="" /></a> </span>It’s a story as old as civilization itself, imprinted in the annals of our collective psyche: the Tower of Babel. In this biblical narrative, a unified humanity once spoke a common language, fostering unparalleled cooperation and innovation. As humanity sought to challenge the divine, constructing a tower reaching for the heavens, God, in response to their hubris, confounded their language, thereby dispersing them across the globe. From this tale was born our world's linguistic diversity, creating both a fascinating richness and a barrier to global understanding. Today, we stand on the brink of a new era, one that could metaphorically undo this ancient division through the magic of technology: Large Language Models, or LLMs.<br><br>

LLMs are artificial intelligence models trained on vast  <a href = 'blog4.html'>Read More</a></p>
				
</div>
</section>
<br>
<br><br><br>
<footer id="footer">
<div class="copyright">
&copy; MPCR Lab <a href="https://mpcrlab.com">Main Site</a>.
</div>
</footer>
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/skel.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>
</body>
</html>
