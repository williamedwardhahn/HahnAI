Traceback (most recent call last):
  File "/home/deepzoo/.local/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 646, in run_until_complete
    return future.result()
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/deepzoo/.local/lib/python3.10/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
#Encode
w0 = CPU(randn_trunc((64,1,4,4)))
w1 = CPU(randn_trunc((128,64,4,4)))
w2 = CPU(randn_trunc((10,6272)))
#Decode
w3 = CPU(randn_trunc((6272,10)))
w4 = CPU(randn_trunc((128,64,4,4)))
w5 = CPU(randn_trunc((64,1,4,4)))

w = [w0,w1,w2,w3,w4,w5]

optimizer = torch.optim.Adam(params=w, lr=learning_rate)

for i in range(num_steps):

    x_real,y = get_batch('train')
    
    x_fake = Autoencoder(x_real,w)
    
    loss = torch.mean((x_fake - x_real)**2)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step() 

    if i % 100 == 0: print(loss.item())
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mKeyboardInterrupt[0m                         Traceback (most recent call last)
Input [0;32mIn [18][0m, in [0;36m<cell line: 14>[0;34m()[0m
[1;32m     20[0m loss [38;5;241m=[39m torch[38;5;241m.[39mmean((x_fake [38;5;241m-[39m x_real)[38;5;241m*[39m[38;5;241m*[39m[38;5;241m2[39m)
[1;32m     22[0m optimizer[38;5;241m.[39mzero_grad()
[0;32m---> 23[0m [43mloss[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[43m)[49m
[1;32m     24[0m optimizer[38;5;241m.[39mstep() 
[1;32m     26[0m [38;5;28;01mif[39;00m i [38;5;241m%[39m [38;5;241m100[39m [38;5;241m==[39m [38;5;241m0[39m: [38;5;28mprint[39m(loss[38;5;241m.[39mitem())

File [0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:396[0m, in [0;36mTensor.backward[0;34m(self, gradient, retain_graph, create_graph, inputs)[0m
[1;32m    387[0m [38;5;28;01mif[39;00m has_torch_function_unary([38;5;28mself[39m):
[1;32m    388[0m     [38;5;28;01mreturn[39;00m handle_torch_function(
[1;32m    389[0m         Tensor[38;5;241m.[39mbackward,
[1;32m    390[0m         ([38;5;28mself[39m,),
[0;32m   (...)[0m
[1;32m    394[0m         create_graph[38;5;241m=[39mcreate_graph,
[1;32m    395[0m         inputs[38;5;241m=[39minputs)
[0;32m--> 396[0m [43mtorch[49m[38;5;241;43m.[39;49m[43mautograd[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43mgradient[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[38;5;241;43m=[39;49m[43minputs[49m[43m)[49m

File [0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173[0m, in [0;36mbackward[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)[0m
[1;32m    168[0m     retain_graph [38;5;241m=[39m create_graph
[1;32m    170[0m [38;5;66;03m# The reason we repeat same the comment below is that[39;00m
[1;32m    171[0m [38;5;66;03m# some Python versions print out the first line of a multi-line function[39;00m
[1;32m    172[0m [38;5;66;03m# calls in the traceback and some print out the last line[39;00m
[0;32m--> 173[0m [43mVariable[49m[38;5;241;43m.[39;49m[43m_execution_engine[49m[38;5;241;43m.[39;49m[43mrun_backward[49m[43m([49m[43m  [49m[38;5;66;43;03m# Calls into the C++ engine to run the backward pass[39;49;00m
[1;32m    174[0m [43m    [49m[43mtensors[49m[43m,[49m[43m [49m[43mgrad_tensors_[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m
[1;32m    175[0m [43m    [49m[43mallow_unreachable[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m[43m [49m[43maccumulate_grad[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m

[0;31mKeyboardInterrupt[0m: 
KeyboardInterrupt: 

